nom du fichier : Metsis_2006_Spam filtering with naive bayes-which naive bayes.pdf

Resum√© : Naive Bayes is very popular in commercial and open-sourceanti-spam e-mail filters. There are, however, several formsof Naive Bayes, something the anti-spam literature does notalways acknowledge. We discuss five different versions ofNaive Bayes, and compare them on six new, non-encodeddatasets, that contain ham messages of particular Enronusers and fresh spam messages. The new datasets, whichwe make publicly available, are more realistic than previouscomparable benchmarks, because they maintain the tempo-ral order of the messages in the two categories, and theyemulate the varying proportion of spam and ham messagesthat users receive over time. We adopt an experimentalprocedure that emulates the incremental training of person-alized spam filters, and we plot roc curves that allow us tocompare the different versions of nb over the entire tradeoffbetween true positives and true negatives.1. INTRODUCTIONAlthough several machine learning algorithms have beenemployed in anti-spam e-mail filtering, including algorithmsthat are considered top-performers in text classification, likeBoosting and Support Vector Machines (see, for example,[4, 6, 10, 16]), Naive Bayes (nb) classifiers currently appearto be particularly popular in commercial and open-sourcespam filters. This is probably due to their simplicity, whichmakes them easy to implement, their linear computationalcomplexity, and their accuracy, which in spam filtering iscomparable to that of more elaborate learning algorithms[2]. There are, however, several forms of nb classifiers, andthe anti-spam literature does not always acknowledge this.In their seminal papers on learning-based spam filters,Sahami et al. [21] used a nb classifier with a multi-variateBernoulli model (this is also the model we had used in [1]), aform of nb that relies on Boolean attributes, whereas Panteland Lin [19] in effect adopted the multinomial form of nb,which normally takes into account term frequencies. Mc-Callum and Nigam [17] have shown experimentally that theThis version of the paper contains some minor correctionsin the description of Flexible Bayes, which were made afterthe conference.Work carried out mostly while at the Department of Infor-matics, Athens University of Economics and Business.CEAS 2006 - Third Conference on Email and Anti-Spam, July 27-28, 2006,Mountain View, California USAmultinomial nb performs generally better than the multi-variate Bernoulli nb in text classification, a finding thatSchneider [24] and Hovold [12] verified with spam filter-ing experiments on Ling-Spam and the pu corpora [1, 2,23]. In further work on text classification, which includedexperiments on Ling-Spam, Schneider [25] found that themultinomial nb surprisingly performs even better when termfrequencies are replaced by Boolean attributes.The multi-variate Bernoulli nb can be modified to accom-modate continuous attributes, leading to what we call themulti-variate Gauss nb, by assuming that the values of eachattribute follow a normal distribution within each category[14]. Alternatively, the distribution of each attribute in eachcategory can be taken to be the average of several normaldistributions, one for every different value the attribute hasin the training data of that category, leading to a nb ver-sion that John and Langley [14] call Flexible Bayes (fb).In previous work [2], we found that fb clearly outperformsthe multi-variate Gauss nb on the pu corpora, when the at-tributes are term frequencies divided by document lengths,but we did not compare fb against the other nb versions.In this paper we shed more light on the five versions ofnb mentioned above, and we evaluate them experimentallyon six new, non-encoded datasets, collectively called Enron-Spam, which we make publicly available.1Each dataset con-tains ham (non-spam) messages from a single user of theEnron corpus [15], to which we have added fresh spam mes-sages with varying ham-spam ratios. Although a similarapproach was adopted in the public benchmark of the trec2005 Spam Track, to be discussed below, we believe thatour datasets are better suited to evaluations of personalizedfilters, i.e., filters that are trained on incoming messages ofa particular user they are intended to protect, which is thetype of filters the experiments of this paper consider. Un-like Ling-Spam and the pu corpora, in the new datasets wemaintain the order in which the original messages of thetwo categories were received, and we emulate the varyingproportion of ham and spam messages that users receiveover time. This allows us to conduct more realistic exper-iments, and to take into account the incremental trainingof personal filters. Furthermore, rather than focussing on ahandful of relative misclassification costs (cost of false posi-tives vs. false negatives;  = 1, 9, 999 in our previous work),1The Enron-Spam datasets are available fromhttp://www.iit.demokritos.gr/skel/i-config/ andhttp://www.aueb.gr/users/ion/publications.html inboth raw and pre-processed form. Ling-Spam and the pucorpora are also available from the same addresses.we plot entire roc curves, which allow us to compare thedifferent versions of nb over the entire tradeoff between truepositives and true negatives.Note that several publicly available spam filters appearto be using techniques described as "Bayesian", but whichare very different from any form of nb discussed in the acad-emic literature and any other technique that would normallybe called Bayesian therein.2Here we focus on nb versionspublished in the academic literature, leaving comparisonsagainst other "Bayesian" techniques for future work.Section 2 below presents the event models and assump-tions of the nb versions we considered. Section 3 explainshow the datasets of our experiments were assembled andthe evaluation methodology we used; it also highlights somepitfalls that have to be avoided when constructing spam fil-tering benchmarks. Section 4 then presents and discussesour experimental results. Section 5 concludes and providesdirections for further work.2. NAIVE BAYES CLASSIFIERSAs a simplification, we focus on the textual content ofthe messages. Operational filters would also consider infor-mation such as the presence of suspicious headers or tokenobfuscation [11, 21], which can be added as additional at-tributes in the message representation discussed below. Al-ternatively, separate classifiers can be trained for textualand other attributes, and then form an ensemble [9, 22].In our experiments, each message is ultimately representedas a vector hx1, . . . , xmi, where x1, . . . , xm are the values ofattributes X1, . . . , Xm, and each attribute provides infor-mation about a particular token of the message.3In thesimplest case, all the attributes are Boolean: Xi = 